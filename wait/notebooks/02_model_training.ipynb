{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_model(model_name, num_classes, pretrained=True):\n",
    "    \"\"\"\n",
    "    Initialize a pre-trained model.\n",
    "    \"\"\"\n",
    "    if model_name == \"efficientnet\":\n",
    "        model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=pretrained)\n",
    "        model.classifier.fc = torch.nn.Linear(model.classifier.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    logging.info(f\"Initialized {model_name} with {num_classes} classes\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, num_classes, device):\n",
    "    \"\"\"\n",
    "    Load the saved model for inference.\n",
    "    \"\"\"\n",
    "    # Initialize the model with the same architecture used during training\n",
    "    model = initialize_model(\"efficientnet\", num_classes, pretrained=False)\n",
    "    \n",
    "    # Load the saved state dictionary\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    # Move the model to the appropriate device (CPU or GPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess the input image for inference.\n",
    "    \"\"\"\n",
    "    # Define the same transformations used during training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to the input size expected by EfficientNet\n",
    "        transforms.ToTensor(),          # Convert to tensor\n",
    "        transforms.Normalize(           # Normalize with the same mean and std used during training\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def infer(model, image_tensor, device):\n",
    "    \"\"\"\n",
    "    Perform inference on a single image.\n",
    "    \"\"\"\n",
    "    # Move the image tensor to the appropriate device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "    \n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\drn20\\anaconda3\\envs\\eml\\Lib\\site-packages\\torch\\hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to C:\\Users\\drn20/.cache\\torch\\hub\\torchhub.zip\n",
      "C:\\Users\\drn20/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\drn20/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Preprocess the input image\\nimage_path = \"path_to_your_image.jpg\"\\nimage_tensor = preprocess_image(image_path)\\n\\n# Perform inference\\npredicted_class = infer(model, image_tensor, device)\\nprint(f\"Predicted class: {predicted_class}\")\\n\\n# Define class names\\nclass_names = [\"asphalt\", \"paving stones\", \"concrete\", \"sett\", \"unpaved\"]  # Adjust as needed\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/road_surface_classification.pth\"\n",
    "num_classes = 5  # Replace with the number of classes used during training\n",
    "model = load_model(model_path, num_classes, device)\n",
    "\"\"\"\n",
    "# Preprocess the input image\n",
    "image_path = \"path_to_your_image.jpg\"\n",
    "image_tensor = preprocess_image(image_path)\n",
    "\n",
    "# Perform inference\n",
    "predicted_class = infer(model, image_tensor, device)\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"asphalt\", \"paving stones\", \"concrete\", \"sett\", \"unpaved\"]  # Adjust as needed\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
