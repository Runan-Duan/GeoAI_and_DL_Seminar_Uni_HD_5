

==> WARNING: A newer version of conda exists. <==
  current version: 23.9.0
  latest version: 25.1.1

Please update conda by running

    $ conda update -n base -c defaults conda

Or to minimize the number of packages updated during conda update use

     conda install conda=25.1.1


2025-03-19 11:00:20,426 - INFO - Logging setup complete.
2025-03-19 11:00:20,427 - INFO - Created directory: data/processed
2025-03-19 11:00:20,427 - INFO - Created directory: models
2025-03-19 11:00:20,428 - INFO - Created directory: logs
2025-03-19 11:00:20,428 - INFO - Created directory: results
2025-03-19 11:00:21,204 - INFO - Data split and saved to data/processed
Downloading: "https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth" to /home/hd/hd_hd/hd_sm330/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-23ab8bcd.pth
  0%|          | 0.00/74.5M [00:00<?, ?B/s] 11%|█         | 8.38M/74.5M [00:00<00:00, 87.7MB/s] 27%|██▋       | 20.1M/74.5M [00:00<00:00, 108MB/s]  42%|████▏     | 31.4M/74.5M [00:00<00:00, 112MB/s] 57%|█████▋    | 42.4M/74.5M [00:00<00:00, 113MB/s] 71%|███████▏  | 53.2M/74.5M [00:00<00:00, 107MB/s] 86%|████████▌ | 64.1M/74.5M [00:00<00:00, 109MB/s]100%|██████████| 74.5M/74.5M [00:00<00:00, 109MB/s]
/home/hd/hd_hd/hd_sm330/.conda/envs/geoai/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
src/train_classifier.py:153: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
/home/hd/hd_hd/hd_sm330/.conda/envs/geoai/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
src/train_classifier.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():  # Mixed precision
2025-03-19 11:00:26,708 - INFO - Train Epoch: 1 [0/8346 (0%)]	Loss: 12.123136	Effective Batch Size: 128
2025-03-19 11:00:43,624 - INFO - Train Epoch: 1 [1600/8346 (19%)]	Loss: 11.244881	Effective Batch Size: 128
2025-03-19 11:01:00,366 - INFO - Train Epoch: 1 [3200/8346 (38%)]	Loss: 6.297138	Effective Batch Size: 128
2025-03-19 11:01:17,106 - INFO - Train Epoch: 1 [4800/8346 (57%)]	Loss: 5.920022	Effective Batch Size: 128
2025-03-19 11:01:33,851 - INFO - Train Epoch: 1 [6400/8346 (77%)]	Loss: 1.360552	Effective Batch Size: 128
2025-03-19 11:01:50,583 - INFO - Train Epoch: 1 [8000/8346 (96%)]	Loss: 0.509285	Effective Batch Size: 128
src/train_classifier.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():  # Mixed precision
2025-03-19 11:01:59,132 - INFO - Validation set: Average loss: 0.0494, Accuracy: 313/776 (40.34%)
2025-03-19 11:01:59,132 - INFO - Epoch 1 - Train Loss: 26.5309, Val Loss: 0.0494, Val Accuracy: 40.34%
2025-03-19 11:01:59,292 - INFO - Model saved to models/best_road_surface_classification.pth
2025-03-19 11:02:01,474 - INFO - Train Epoch: 2 [0/8346 (0%)]	Loss: 0.388524	Effective Batch Size: 128
2025-03-19 11:02:18,251 - INFO - Train Epoch: 2 [1600/8346 (19%)]	Loss: 0.379040	Effective Batch Size: 128
2025-03-19 11:02:34,987 - INFO - Train Epoch: 2 [3200/8346 (38%)]	Loss: 0.388226	Effective Batch Size: 128
2025-03-19 11:02:51,713 - INFO - Train Epoch: 2 [4800/8346 (57%)]	Loss: 0.413113	Effective Batch Size: 128
2025-03-19 11:03:08,444 - INFO - Train Epoch: 2 [6400/8346 (77%)]	Loss: 0.371121	Effective Batch Size: 128
2025-03-19 11:03:25,172 - INFO - Train Epoch: 2 [8000/8346 (96%)]	Loss: 0.339994	Effective Batch Size: 128
2025-03-19 11:03:31,769 - INFO - Validation set: Average loss: 0.0395, Accuracy: 528/776 (68.04%)
2025-03-19 11:03:31,770 - INFO - Epoch 2 - Train Loss: 1.4819, Val Loss: 0.0395, Val Accuracy: 68.04%
2025-03-19 11:03:31,925 - INFO - Model saved to models/best_road_surface_classification.pth
2025-03-19 11:03:34,129 - INFO - Train Epoch: 3 [0/8346 (0%)]	Loss: 0.282877	Effective Batch Size: 128
2025-03-19 11:03:50,895 - INFO - Train Epoch: 3 [1600/8346 (19%)]	Loss: 0.297857	Effective Batch Size: 128
2025-03-19 11:04:07,655 - INFO - Train Epoch: 3 [3200/8346 (38%)]	Loss: 0.301359	Effective Batch Size: 128
2025-03-19 11:04:24,406 - INFO - Train Epoch: 3 [4800/8346 (57%)]	Loss: 0.220333	Effective Batch Size: 128
2025-03-19 11:04:41,161 - INFO - Train Epoch: 3 [6400/8346 (77%)]	Loss: 0.299052	Effective Batch Size: 128
2025-03-19 11:04:57,903 - INFO - Train Epoch: 3 [8000/8346 (96%)]	Loss: 0.251152	Effective Batch Size: 128
2025-03-19 11:05:04,624 - INFO - Validation set: Average loss: 0.0306, Accuracy: 594/776 (76.55%)
2025-03-19 11:05:04,624 - INFO - Epoch 3 - Train Loss: 1.1625, Val Loss: 0.0306, Val Accuracy: 76.55%
2025-03-19 11:05:04,773 - INFO - Model saved to models/best_road_surface_classification.pth
2025-03-19 11:05:07,059 - INFO - Train Epoch: 4 [0/8346 (0%)]	Loss: 0.293794	Effective Batch Size: 128
2025-03-19 11:05:23,810 - INFO - Train Epoch: 4 [1600/8346 (19%)]	Loss: 0.217846	Effective Batch Size: 128
2025-03-19 11:05:40,546 - INFO - Train Epoch: 4 [3200/8346 (38%)]	Loss: 0.256957	Effective Batch Size: 128
2025-03-19 11:05:57,276 - INFO - Train Epoch: 4 [4800/8346 (57%)]	Loss: 0.274732	Effective Batch Size: 128
2025-03-19 11:06:14,016 - INFO - Train Epoch: 4 [6400/8346 (77%)]	Loss: 0.216308	Effective Batch Size: 128
2025-03-19 11:06:30,748 - INFO - Train Epoch: 4 [8000/8346 (96%)]	Loss: 0.222979	Effective Batch Size: 128
2025-03-19 11:06:37,455 - INFO - Validation set: Average loss: 0.0300, Accuracy: 627/776 (80.80%)
2025-03-19 11:06:37,455 - INFO - Epoch 4 - Train Loss: 1.0328, Val Loss: 0.0300, Val Accuracy: 80.80%
2025-03-19 11:06:37,603 - INFO - Model saved to models/best_road_surface_classification.pth
2025-03-19 11:06:39,750 - INFO - Train Epoch: 5 [0/8346 (0%)]	Loss: 0.202816	Effective Batch Size: 128
2025-03-19 11:06:56,493 - INFO - Train Epoch: 5 [1600/8346 (19%)]	Loss: 0.251640	Effective Batch Size: 128
2025-03-19 11:07:13,236 - INFO - Train Epoch: 5 [3200/8346 (38%)]	Loss: 0.182061	Effective Batch Size: 128
2025-03-19 11:07:29,972 - INFO - Train Epoch: 5 [4800/8346 (57%)]	Loss: 0.237204	Effective Batch Size: 128
2025-03-19 11:07:46,757 - INFO - Train Epoch: 5 [6400/8346 (77%)]	Loss: 0.189922	Effective Batch Size: 128
2025-03-19 11:08:03,511 - INFO - Train Epoch: 5 [8000/8346 (96%)]	Loss: 0.243996	Effective Batch Size: 128
2025-03-19 11:08:10,171 - INFO - Validation set: Average loss: 0.0283, Accuracy: 620/776 (79.90%)
2025-03-19 11:08:10,172 - INFO - Epoch 5 - Train Loss: 0.9450, Val Loss: 0.0283, Val Accuracy: 79.90%
2025-03-19 11:08:10,320 - INFO - Model saved to models/best_road_surface_classification.pth
2025-03-19 11:08:12,483 - INFO - Train Epoch: 6 [0/8346 (0%)]	Loss: 0.264302	Effective Batch Size: 128
2025-03-19 11:08:29,233 - INFO - Train Epoch: 6 [1600/8346 (19%)]	Loss: 0.248395	Effective Batch Size: 128
2025-03-19 11:08:45,980 - INFO - Train Epoch: 6 [3200/8346 (38%)]	Loss: 0.172527	Effective Batch Size: 128
2025-03-19 11:09:02,715 - INFO - Train Epoch: 6 [4800/8346 (57%)]	Loss: 0.191095	Effective Batch Size: 128
2025-03-19 11:09:19,455 - INFO - Train Epoch: 6 [6400/8346 (77%)]	Loss: 0.292595	Effective Batch Size: 128
2025-03-19 11:09:36,187 - INFO - Train Epoch: 6 [8000/8346 (96%)]	Loss: 0.225256	Effective Batch Size: 128
2025-03-19 11:09:42,952 - INFO - Validation set: Average loss: 0.0339, Accuracy: 577/776 (74.36%)
2025-03-19 11:09:42,953 - INFO - Epoch 6 - Train Loss: 0.9053, Val Loss: 0.0339, Val Accuracy: 74.36%
2025-03-19 11:09:45,306 - INFO - Train Epoch: 7 [0/8346 (0%)]	Loss: 0.295883	Effective Batch Size: 128
2025-03-19 11:10:02,051 - INFO - Train Epoch: 7 [1600/8346 (19%)]	Loss: 0.238455	Effective Batch Size: 128
2025-03-19 11:10:18,796 - INFO - Train Epoch: 7 [3200/8346 (38%)]	Loss: 0.209927	Effective Batch Size: 128
2025-03-19 11:10:35,532 - INFO - Train Epoch: 7 [4800/8346 (57%)]	Loss: 0.253905	Effective Batch Size: 128
2025-03-19 11:10:52,271 - INFO - Train Epoch: 7 [6400/8346 (77%)]	Loss: 0.212718	Effective Batch Size: 128
2025-03-19 11:11:08,999 - INFO - Train Epoch: 7 [8000/8346 (96%)]	Loss: 0.257434	Effective Batch Size: 128
2025-03-19 11:11:15,722 - INFO - Validation set: Average loss: 0.0332, Accuracy: 564/776 (72.68%)
2025-03-19 11:11:15,723 - INFO - Epoch 7 - Train Loss: 0.8865, Val Loss: 0.0332, Val Accuracy: 72.68%
2025-03-19 11:11:17,809 - INFO - Train Epoch: 8 [0/8346 (0%)]	Loss: 0.219074	Effective Batch Size: 128
2025-03-19 11:11:34,565 - INFO - Train Epoch: 8 [1600/8346 (19%)]	Loss: 0.233523	Effective Batch Size: 128
2025-03-19 11:11:51,318 - INFO - Train Epoch: 8 [3200/8346 (38%)]	Loss: 0.239394	Effective Batch Size: 128
2025-03-19 11:12:08,052 - INFO - Train Epoch: 8 [4800/8346 (57%)]	Loss: 0.165286	Effective Batch Size: 128
2025-03-19 11:12:24,797 - INFO - Train Epoch: 8 [6400/8346 (77%)]	Loss: 0.202665	Effective Batch Size: 128
2025-03-19 11:12:41,530 - INFO - Train Epoch: 8 [8000/8346 (96%)]	Loss: 0.284775	Effective Batch Size: 128
2025-03-19 11:12:48,225 - INFO - Validation set: Average loss: 0.0294, Accuracy: 607/776 (78.22%)
2025-03-19 11:12:48,225 - INFO - Epoch 8 - Train Loss: 0.8713, Val Loss: 0.0294, Val Accuracy: 78.22%
2025-03-19 11:12:50,470 - INFO - Train Epoch: 9 [0/8346 (0%)]	Loss: 0.175979	Effective Batch Size: 128
2025-03-19 11:13:07,219 - INFO - Train Epoch: 9 [1600/8346 (19%)]	Loss: 0.199675	Effective Batch Size: 128
2025-03-19 11:13:23,967 - INFO - Train Epoch: 9 [3200/8346 (38%)]	Loss: 0.183081	Effective Batch Size: 128
2025-03-19 11:13:40,709 - INFO - Train Epoch: 9 [4800/8346 (57%)]	Loss: 0.209111	Effective Batch Size: 128
2025-03-19 11:13:57,458 - INFO - Train Epoch: 9 [6400/8346 (77%)]	Loss: 0.240522	Effective Batch Size: 128
2025-03-19 11:14:14,194 - INFO - Train Epoch: 9 [8000/8346 (96%)]	Loss: 0.272740	Effective Batch Size: 128
2025-03-19 11:14:20,806 - INFO - Validation set: Average loss: 0.0264, Accuracy: 648/776 (83.51%)
2025-03-19 11:14:20,806 - INFO - Epoch 9 - Train Loss: 0.8893, Val Loss: 0.0264, Val Accuracy: 83.51%
2025-03-19 11:14:21,034 - INFO - Model saved to models/best_road_surface_classification.pth
2025-03-19 11:14:23,679 - INFO - Train Epoch: 10 [0/8346 (0%)]	Loss: 0.188999	Effective Batch Size: 128
2025-03-19 11:14:40,427 - INFO - Train Epoch: 10 [1600/8346 (19%)]	Loss: 0.233512	Effective Batch Size: 128
2025-03-19 11:14:57,162 - INFO - Train Epoch: 10 [3200/8346 (38%)]	Loss: 0.200289	Effective Batch Size: 128
2025-03-19 11:15:13,886 - INFO - Train Epoch: 10 [4800/8346 (57%)]	Loss: 0.235805	Effective Batch Size: 128
2025-03-19 11:15:30,622 - INFO - Train Epoch: 10 [6400/8346 (77%)]	Loss: 0.202270	Effective Batch Size: 128
2025-03-19 11:15:47,344 - INFO - Train Epoch: 10 [8000/8346 (96%)]	Loss: 0.224971	Effective Batch Size: 128
2025-03-19 11:15:54,072 - INFO - Validation set: Average loss: 0.0238, Accuracy: 660/776 (85.05%)
2025-03-19 11:15:54,072 - INFO - Epoch 10 - Train Loss: 0.8920, Val Loss: 0.0238, Val Accuracy: 85.05%
2025-03-19 11:15:54,229 - INFO - Model saved to models/best_road_surface_classification.pth
2025-03-19 11:15:56,432 - INFO - Train Epoch: 11 [0/8346 (0%)]	Loss: 0.188717	Effective Batch Size: 128
2025-03-19 11:16:13,184 - INFO - Train Epoch: 11 [1600/8346 (19%)]	Loss: 0.253771	Effective Batch Size: 128
2025-03-19 11:16:30,310 - INFO - Train Epoch: 11 [3200/8346 (38%)]	Loss: 0.205410	Effective Batch Size: 128
2025-03-19 11:16:47,054 - INFO - Train Epoch: 11 [4800/8346 (57%)]	Loss: 0.223587	Effective Batch Size: 128
2025-03-19 11:17:03,797 - INFO - Train Epoch: 11 [6400/8346 (77%)]	Loss: 0.202019	Effective Batch Size: 128
2025-03-19 11:17:20,528 - INFO - Train Epoch: 11 [8000/8346 (96%)]	Loss: 0.247981	Effective Batch Size: 128
2025-03-19 11:17:27,210 - INFO - Validation set: Average loss: 0.0314, Accuracy: 595/776 (76.68%)
2025-03-19 11:17:27,211 - INFO - Epoch 11 - Train Loss: 0.8898, Val Loss: 0.0314, Val Accuracy: 76.68%
2025-03-19 11:17:29,321 - INFO - Train Epoch: 12 [0/8346 (0%)]	Loss: 0.172461	Effective Batch Size: 128
2025-03-19 11:17:46,061 - INFO - Train Epoch: 12 [1600/8346 (19%)]	Loss: 0.289101	Effective Batch Size: 128
2025-03-19 11:18:02,801 - INFO - Train Epoch: 12 [3200/8346 (38%)]	Loss: 0.200718	Effective Batch Size: 128
2025-03-19 11:18:19,533 - INFO - Train Epoch: 12 [4800/8346 (57%)]	Loss: 0.253653	Effective Batch Size: 128
2025-03-19 11:18:36,267 - INFO - Train Epoch: 12 [6400/8346 (77%)]	Loss: 0.241374	Effective Batch Size: 128
2025-03-19 11:18:52,992 - INFO - Train Epoch: 12 [8000/8346 (96%)]	Loss: 0.229577	Effective Batch Size: 128
2025-03-19 11:18:59,691 - INFO - Validation set: Average loss: 0.0326, Accuracy: 561/776 (72.29%)
2025-03-19 11:18:59,691 - INFO - Epoch 12 - Train Loss: 0.8913, Val Loss: 0.0326, Val Accuracy: 72.29%
2025-03-19 11:19:01,927 - INFO - Train Epoch: 13 [0/8346 (0%)]	Loss: 0.217743	Effective Batch Size: 128
2025-03-19 11:19:18,721 - INFO - Train Epoch: 13 [1600/8346 (19%)]	Loss: 0.274858	Effective Batch Size: 128
2025-03-19 11:19:35,495 - INFO - Train Epoch: 13 [3200/8346 (38%)]	Loss: 0.195542	Effective Batch Size: 128
2025-03-19 11:19:52,258 - INFO - Train Epoch: 13 [4800/8346 (57%)]	Loss: 0.225626	Effective Batch Size: 128
2025-03-19 11:20:09,015 - INFO - Train Epoch: 13 [6400/8346 (77%)]	Loss: 0.216110	Effective Batch Size: 128
2025-03-19 11:20:25,754 - INFO - Train Epoch: 13 [8000/8346 (96%)]	Loss: 0.221394	Effective Batch Size: 128
2025-03-19 11:20:32,469 - INFO - Validation set: Average loss: 0.0334, Accuracy: 531/776 (68.43%)
2025-03-19 11:20:32,469 - INFO - Epoch 13 - Train Loss: 0.8992, Val Loss: 0.0334, Val Accuracy: 68.43%
2025-03-19 11:20:34,795 - INFO - Train Epoch: 14 [0/8346 (0%)]	Loss: 0.243572	Effective Batch Size: 128
2025-03-19 11:20:51,543 - INFO - Train Epoch: 14 [1600/8346 (19%)]	Loss: 0.172702	Effective Batch Size: 128
2025-03-19 11:21:08,282 - INFO - Train Epoch: 14 [3200/8346 (38%)]	Loss: 0.198833	Effective Batch Size: 128
2025-03-19 11:21:25,012 - INFO - Train Epoch: 14 [4800/8346 (57%)]	Loss: 0.203070	Effective Batch Size: 128
2025-03-19 11:21:41,749 - INFO - Train Epoch: 14 [6400/8346 (77%)]	Loss: 0.217851	Effective Batch Size: 128
2025-03-19 11:21:58,479 - INFO - Train Epoch: 14 [8000/8346 (96%)]	Loss: 0.241959	Effective Batch Size: 128
2025-03-19 11:22:05,100 - INFO - Validation set: Average loss: 0.0310, Accuracy: 595/776 (76.68%)
2025-03-19 11:22:05,101 - INFO - Epoch 14 - Train Loss: 0.8985, Val Loss: 0.0310, Val Accuracy: 76.68%
2025-03-19 11:22:07,434 - INFO - Train Epoch: 15 [0/8346 (0%)]	Loss: 0.191075	Effective Batch Size: 128
2025-03-19 11:22:24,207 - INFO - Train Epoch: 15 [1600/8346 (19%)]	Loss: 0.157408	Effective Batch Size: 128
2025-03-19 11:22:40,963 - INFO - Train Epoch: 15 [3200/8346 (38%)]	Loss: 0.183611	Effective Batch Size: 128
2025-03-19 11:22:57,689 - INFO - Train Epoch: 15 [4800/8346 (57%)]	Loss: 0.200527	Effective Batch Size: 128
2025-03-19 11:23:14,420 - INFO - Train Epoch: 15 [6400/8346 (77%)]	Loss: 0.200718	Effective Batch Size: 128
2025-03-19 11:23:31,142 - INFO - Train Epoch: 15 [8000/8346 (96%)]	Loss: 0.190875	Effective Batch Size: 128
2025-03-19 11:23:37,830 - INFO - Validation set: Average loss: 0.0261, Accuracy: 627/776 (80.80%)
2025-03-19 11:23:37,831 - INFO - Epoch 15 - Train Loss: 0.7751, Val Loss: 0.0261, Val Accuracy: 80.80%
2025-03-19 11:23:40,189 - INFO - Train Epoch: 16 [0/8346 (0%)]	Loss: 0.122497	Effective Batch Size: 128
2025-03-19 11:23:56,944 - INFO - Train Epoch: 16 [1600/8346 (19%)]	Loss: 0.150959	Effective Batch Size: 128
2025-03-19 11:24:13,676 - INFO - Train Epoch: 16 [3200/8346 (38%)]	Loss: 0.174756	Effective Batch Size: 128
2025-03-19 11:24:30,408 - INFO - Train Epoch: 16 [4800/8346 (57%)]	Loss: 0.181645	Effective Batch Size: 128
2025-03-19 11:24:47,141 - INFO - Train Epoch: 16 [6400/8346 (77%)]	Loss: 0.181128	Effective Batch Size: 128
2025-03-19 11:25:03,863 - INFO - Train Epoch: 16 [8000/8346 (96%)]	Loss: 0.173592	Effective Batch Size: 128
2025-03-19 11:25:10,559 - INFO - Validation set: Average loss: 0.0257, Accuracy: 627/776 (80.80%)
2025-03-19 11:25:10,559 - INFO - Epoch 16 - Train Loss: 0.7251, Val Loss: 0.0257, Val Accuracy: 80.80%
2025-03-19 11:25:12,905 - INFO - Train Epoch: 17 [0/8346 (0%)]	Loss: 0.195288	Effective Batch Size: 128
2025-03-19 11:25:29,643 - INFO - Train Epoch: 17 [1600/8346 (19%)]	Loss: 0.211162	Effective Batch Size: 128
2025-03-19 11:25:46,384 - INFO - Train Epoch: 17 [3200/8346 (38%)]	Loss: 0.166095	Effective Batch Size: 128
2025-03-19 11:26:03,110 - INFO - Train Epoch: 17 [4800/8346 (57%)]	Loss: 0.152471	Effective Batch Size: 128
2025-03-19 11:26:19,847 - INFO - Train Epoch: 17 [6400/8346 (77%)]	Loss: 0.153424	Effective Batch Size: 128
2025-03-19 11:26:36,572 - INFO - Train Epoch: 17 [8000/8346 (96%)]	Loss: 0.217140	Effective Batch Size: 128
2025-03-19 11:26:43,360 - INFO - Validation set: Average loss: 0.0247, Accuracy: 637/776 (82.09%)
2025-03-19 11:26:43,360 - INFO - Epoch 17 - Train Loss: 0.6959, Val Loss: 0.0247, Val Accuracy: 82.09%
2025-03-19 11:26:45,639 - INFO - Train Epoch: 18 [0/8346 (0%)]	Loss: 0.166056	Effective Batch Size: 128
2025-03-19 11:27:02,379 - INFO - Train Epoch: 18 [1600/8346 (19%)]	Loss: 0.205137	Effective Batch Size: 128
2025-03-19 11:27:19,120 - INFO - Train Epoch: 18 [3200/8346 (38%)]	Loss: 0.156098	Effective Batch Size: 128
2025-03-19 11:27:35,851 - INFO - Train Epoch: 18 [4800/8346 (57%)]	Loss: 0.165774	Effective Batch Size: 128
2025-03-19 11:27:52,588 - INFO - Train Epoch: 18 [6400/8346 (77%)]	Loss: 0.178007	Effective Batch Size: 128
2025-03-19 11:28:09,316 - INFO - Train Epoch: 18 [8000/8346 (96%)]	Loss: 0.153764	Effective Batch Size: 128
2025-03-19 11:28:16,016 - INFO - Validation set: Average loss: 0.0272, Accuracy: 608/776 (78.35%)
2025-03-19 11:28:16,016 - INFO - Epoch 18 - Train Loss: 0.6820, Val Loss: 0.0272, Val Accuracy: 78.35%
2025-03-19 11:28:18,322 - INFO - Train Epoch: 19 [0/8346 (0%)]	Loss: 0.195563	Effective Batch Size: 128
2025-03-19 11:28:35,062 - INFO - Train Epoch: 19 [1600/8346 (19%)]	Loss: 0.195559	Effective Batch Size: 128
2025-03-19 11:28:51,799 - INFO - Train Epoch: 19 [3200/8346 (38%)]	Loss: 0.144244	Effective Batch Size: 128
2025-03-19 11:29:08,526 - INFO - Train Epoch: 19 [4800/8346 (57%)]	Loss: 0.139514	Effective Batch Size: 128
2025-03-19 11:29:25,258 - INFO - Train Epoch: 19 [6400/8346 (77%)]	Loss: 0.193335	Effective Batch Size: 128
2025-03-19 11:29:41,983 - INFO - Train Epoch: 19 [8000/8346 (96%)]	Loss: 0.173458	Effective Batch Size: 128
2025-03-19 11:29:48,622 - INFO - Validation set: Average loss: 0.0249, Accuracy: 636/776 (81.96%)
2025-03-19 11:29:48,623 - INFO - Epoch 19 - Train Loss: 0.6633, Val Loss: 0.0249, Val Accuracy: 81.96%
2025-03-19 11:29:50,833 - INFO - Train Epoch: 20 [0/8346 (0%)]	Loss: 0.182631	Effective Batch Size: 128
2025-03-19 11:30:07,563 - INFO - Train Epoch: 20 [1600/8346 (19%)]	Loss: 0.130772	Effective Batch Size: 128
2025-03-19 11:30:24,300 - INFO - Train Epoch: 20 [3200/8346 (38%)]	Loss: 0.137284	Effective Batch Size: 128
2025-03-19 11:30:41,026 - INFO - Train Epoch: 20 [4800/8346 (57%)]	Loss: 0.132869	Effective Batch Size: 128
2025-03-19 11:30:57,762 - INFO - Train Epoch: 20 [6400/8346 (77%)]	Loss: 0.146563	Effective Batch Size: 128
2025-03-19 11:31:14,485 - INFO - Train Epoch: 20 [8000/8346 (96%)]	Loss: 0.142825	Effective Batch Size: 128
2025-03-19 11:31:21,169 - INFO - Validation set: Average loss: 0.0263, Accuracy: 620/776 (79.90%)
2025-03-19 11:31:21,170 - INFO - Epoch 20 - Train Loss: 0.6359, Val Loss: 0.0263, Val Accuracy: 79.90%
2025-03-19 11:31:23,326 - INFO - Train Epoch: 21 [0/8346 (0%)]	Loss: 0.132144	Effective Batch Size: 128
2025-03-19 11:31:40,078 - INFO - Train Epoch: 21 [1600/8346 (19%)]	Loss: 0.175361	Effective Batch Size: 128
2025-03-19 11:31:56,819 - INFO - Train Epoch: 21 [3200/8346 (38%)]	Loss: 0.151374	Effective Batch Size: 128
2025-03-19 11:32:13,545 - INFO - Train Epoch: 21 [4800/8346 (57%)]	Loss: 0.194613	Effective Batch Size: 128
2025-03-19 11:32:30,277 - INFO - Train Epoch: 21 [6400/8346 (77%)]	Loss: 0.145786	Effective Batch Size: 128
2025-03-19 11:32:47,001 - INFO - Train Epoch: 21 [8000/8346 (96%)]	Loss: 0.142976	Effective Batch Size: 128
2025-03-19 11:32:53,704 - INFO - Validation set: Average loss: 0.0266, Accuracy: 607/776 (78.22%)
2025-03-19 11:32:53,705 - INFO - Epoch 21 - Train Loss: 0.6310, Val Loss: 0.0266, Val Accuracy: 78.22%
2025-03-19 11:32:55,886 - INFO - Train Epoch: 22 [0/8346 (0%)]	Loss: 0.150177	Effective Batch Size: 128
2025-03-19 11:33:12,658 - INFO - Train Epoch: 22 [1600/8346 (19%)]	Loss: 0.185067	Effective Batch Size: 128
2025-03-19 11:33:29,398 - INFO - Train Epoch: 22 [3200/8346 (38%)]	Loss: 0.167776	Effective Batch Size: 128
2025-03-19 11:33:46,126 - INFO - Train Epoch: 22 [4800/8346 (57%)]	Loss: 0.168740	Effective Batch Size: 128
2025-03-19 11:34:02,865 - INFO - Train Epoch: 22 [6400/8346 (77%)]	Loss: 0.173597	Effective Batch Size: 128
2025-03-19 11:34:19,588 - INFO - Train Epoch: 22 [8000/8346 (96%)]	Loss: 0.134364	Effective Batch Size: 128
2025-03-19 11:34:26,265 - INFO - Validation set: Average loss: 0.0262, Accuracy: 614/776 (79.12%)
2025-03-19 11:34:26,266 - INFO - Epoch 22 - Train Loss: 0.6234, Val Loss: 0.0262, Val Accuracy: 79.12%
2025-03-19 11:34:28,424 - INFO - Train Epoch: 23 [0/8346 (0%)]	Loss: 0.141385	Effective Batch Size: 128
2025-03-19 11:34:45,192 - INFO - Train Epoch: 23 [1600/8346 (19%)]	Loss: 0.168646	Effective Batch Size: 128
2025-03-19 11:35:01,939 - INFO - Train Epoch: 23 [3200/8346 (38%)]	Loss: 0.170114	Effective Batch Size: 128
2025-03-19 11:35:18,669 - INFO - Train Epoch: 23 [4800/8346 (57%)]	Loss: 0.151198	Effective Batch Size: 128
2025-03-19 11:35:35,403 - INFO - Train Epoch: 23 [6400/8346 (77%)]	Loss: 0.167630	Effective Batch Size: 128
2025-03-19 11:35:52,295 - INFO - Train Epoch: 23 [8000/8346 (96%)]	Loss: 0.123763	Effective Batch Size: 128
2025-03-19 11:35:59,235 - INFO - Validation set: Average loss: 0.0259, Accuracy: 618/776 (79.64%)
2025-03-19 11:35:59,235 - INFO - Epoch 23 - Train Loss: 0.6264, Val Loss: 0.0259, Val Accuracy: 79.64%
2025-03-19 11:36:01,385 - INFO - Train Epoch: 24 [0/8346 (0%)]	Loss: 0.156974	Effective Batch Size: 128
2025-03-19 11:36:18,130 - INFO - Train Epoch: 24 [1600/8346 (19%)]	Loss: 0.160482	Effective Batch Size: 128
2025-03-19 11:36:34,871 - INFO - Train Epoch: 24 [3200/8346 (38%)]	Loss: 0.123868	Effective Batch Size: 128
2025-03-19 11:36:51,622 - INFO - Train Epoch: 24 [4800/8346 (57%)]	Loss: 0.180049	Effective Batch Size: 128
2025-03-19 11:37:08,359 - INFO - Train Epoch: 24 [6400/8346 (77%)]	Loss: 0.165807	Effective Batch Size: 128
2025-03-19 11:37:25,088 - INFO - Train Epoch: 24 [8000/8346 (96%)]	Loss: 0.179097	Effective Batch Size: 128
2025-03-19 11:37:31,977 - INFO - Validation set: Average loss: 0.0269, Accuracy: 602/776 (77.58%)
2025-03-19 11:37:31,978 - INFO - Epoch 24 - Train Loss: 0.6249, Val Loss: 0.0269, Val Accuracy: 77.58%
2025-03-19 11:37:34,203 - INFO - Train Epoch: 25 [0/8346 (0%)]	Loss: 0.191450	Effective Batch Size: 128
2025-03-19 11:37:50,935 - INFO - Train Epoch: 25 [1600/8346 (19%)]	Loss: 0.163564	Effective Batch Size: 128
2025-03-19 11:38:07,679 - INFO - Train Epoch: 25 [3200/8346 (38%)]	Loss: 0.155820	Effective Batch Size: 128
2025-03-19 11:38:24,407 - INFO - Train Epoch: 25 [4800/8346 (57%)]	Loss: 0.196669	Effective Batch Size: 128
2025-03-19 11:38:41,137 - INFO - Train Epoch: 25 [6400/8346 (77%)]	Loss: 0.175213	Effective Batch Size: 128
2025-03-19 11:38:58,868 - INFO - Train Epoch: 25 [8000/8346 (96%)]	Loss: 0.159553	Effective Batch Size: 128
2025-03-19 11:39:05,643 - INFO - Validation set: Average loss: 0.0258, Accuracy: 619/776 (79.77%)
2025-03-19 11:39:05,644 - INFO - Epoch 25 - Train Loss: 0.6212, Val Loss: 0.0258, Val Accuracy: 79.77%
2025-03-19 11:39:05,644 - INFO - Early stopping triggered!
2025-03-19 11:39:05,890 - INFO - Model saved to models/final_road_surface_classification.pth
2025-03-19 11:39:49,492 - INFO - Logging setup complete.
/pfs/data5/home/hd/hd_hd/hd_sm330/project/myproject/src/utils/utils.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(path, map_location=device))
2025-03-19 11:39:50,964 - INFO - Model loaded from models/best_road_surface_classification.pth
src/evaluate.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():  # Mixed precision
2025-03-19 11:40:08,641 - INFO - Test Loss: 0.0239
2025-03-19 11:40:08,641 - INFO - Test Accuracy: 40518.17%
2025-03-19 11:40:08,641 - INFO - Confusion Matrix:
[[  1  15   0   0   0]
 [ 16 504   2   6   2]
 [ 58  25   1   0   1]
 [  4  22   1  79   7]
 [  4   3   1   5  19]]
2025-03-19 11:40:08,641 - INFO - Classification Report:
               precision    recall  f1-score   support

      asphalt       0.01      0.06      0.02        16
     concrete       0.89      0.95      0.92       530
paving_stones       0.20      0.01      0.02        85
         sett       0.88      0.70      0.78       113
      unpaved       0.66      0.59      0.62        32

     accuracy                           0.78       776
    macro avg       0.53      0.46      0.47       776
 weighted avg       0.78      0.78      0.77       776

Traceback (most recent call last):
  File "src/evaluate.py", line 193, in <module>
    main()
  File "src/evaluate.py", line 179, in main
    visualize_classification_predictions(
  File "/pfs/data5/home/hd/hd_hd/hd_sm330/project/myproject/src/visualization/visualize_predictions.py", line 14, in visualize_classification_predictions
    image = image.permute(1, 2, 0).cpu().numpy()  # Convert to HWC format
AttributeError: 'str' object has no attribute 'permute'
2025-03-19 11:40:14,468 - INFO - Logging setup complete.
/pfs/data5/home/hd/hd_hd/hd_sm330/project/myproject/src/utils/utils.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(path, map_location=device))
2025-03-19 11:40:15,645 - INFO - Model loaded from models/final_road_surface_classification.pth
src/evaluate.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():  # Mixed precision
2025-03-19 11:40:33,359 - INFO - Test Loss: 0.0959
2025-03-19 11:40:33,360 - INFO - Test Accuracy: 13247.29%
2025-03-19 11:40:33,360 - INFO - Confusion Matrix:
[[  2   1   2   3  24]
 [ 75   8   2   0   0]
 [  1   5   9   1   0]
 [ 17 423  71  14   5]
 [  1   9   7  88   8]]
2025-03-19 11:40:33,360 - INFO - Classification Report:
               precision    recall  f1-score   support

      asphalt       0.02      0.06      0.03        32
     concrete       0.02      0.09      0.03        85
paving_stones       0.10      0.56      0.17        16
         sett       0.13      0.03      0.04       530
      unpaved       0.22      0.07      0.11       113

     accuracy                           0.05       776
    macro avg       0.10      0.16      0.08       776
 weighted avg       0.13      0.05      0.05       776

Traceback (most recent call last):
  File "src/evaluate.py", line 193, in <module>
    main()
  File "src/evaluate.py", line 179, in main
    visualize_classification_predictions(
  File "/pfs/data5/home/hd/hd_hd/hd_sm330/project/myproject/src/visualization/visualize_predictions.py", line 14, in visualize_classification_predictions
    image = image.permute(1, 2, 0).cpu().numpy()  # Convert to HWC format
AttributeError: 'str' object has no attribute 'permute'
